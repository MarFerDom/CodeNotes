{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed004f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp others_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69432b9e",
   "metadata": {},
   "source": [
    "<a id=top></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade05d2b",
   "metadata": {},
   "source": [
    "# Open AI\n",
    "\n",
    "> Using OpenAi's API calls and prompt engineering\n",
    "\n",
    "- skip_exec: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36272fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd54a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd690e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complet(prompt, model='gpt-3.5-turbo', temperature=0):\n",
    "    messages = [{'role':'user', 'content':prompt}]\n",
    "    resp = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature)\n",
    "    \n",
    "    return resp.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c24d33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Disappointment\n",
      "2. Uncertainty\n",
      "3. Skepticism\n",
      "4. Pessimism\n",
      "5. Apprehension\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "Cite the 5 more relevant sentiments related to the following text surrounded by ```\n",
    "\n",
    "```I think this is not going to be quite what you expect```\n",
    "'''\n",
    "response = get_complet(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e838f92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Population Stability Index (PSI) is a statistical measure used to assess the stability of a population over time. It is commonly used in the field of credit risk management to monitor changes in the creditworthiness of a portfolio of borrowers. The PSI is calculated by following these steps:\n",
      "\n",
      "1. Divide the population into two groups: the reference group and the comparison group. The reference group is typically the population at a specific point in time, such as the current year, while the comparison group is the population at a previous point in time, such as the previous year.\n",
      "\n",
      "2. Calculate the percentage of each group in each of several predefined score ranges. For example, if the score range is 0-100, the percentage of borrowers in each range would be calculated for both the reference and comparison groups.\n",
      "\n",
      "3. Calculate the expected percentage of borrowers in each score range for the reference group. This can be done by multiplying the total number of borrowers in the reference group by the percentage of borrowers in each score range.\n",
      "\n",
      "4. Calculate the actual percentage of borrowers in each score range for the comparison group. This can be done by multiplying the total number of borrowers in the comparison group by the percentage of borrowers in each score range.\n",
      "\n",
      "5. Calculate the PSI for each score range by using the following formula: PSI = (Actual Percentage - Expected Percentage) * ln(Actual Percentage / Expected Percentage)\n",
      "\n",
      "6. Sum the PSI values for all score ranges to obtain the overall PSI for the population.\n",
      "\n",
      "A PSI value of less than 0.1 is generally considered to indicate a stable population, while a value greater than 0.25 indicates significant changes in the population. The PSI can be used to identify areas of the population that are experiencing significant changes, which can help lenders to adjust their risk management strategies accordingly.\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "Present in a technical and objective manner the steps for calculating the Population Stability Index.\n",
    "'''\n",
    "response = get_complet(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22c50bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table>\n",
      "  <tr>\n",
      "    <th>Method</th>\n",
      "    <th>Pros</th>\n",
      "    <th>Cons</th>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>KS-test</td>\n",
      "    <td>Easy to implement, widely used, suitable for continuous data</td>\n",
      "    <td>Assumes normal distribution, may not work well for small sample sizes</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>t-test</td>\n",
      "    <td>Easy to implement, widely used, suitable for continuous data</td>\n",
      "    <td>Assumes normal distribution, may not work well for small sample sizes, requires equal variances</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Jensen-Shannon</td>\n",
      "    <td>Works well for both continuous and discrete data, does not assume normal distribution</td>\n",
      "    <td>May be computationally expensive for large datasets, may not work well for high-dimensional data</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Wasserstein distance</td>\n",
      "    <td>Works well for both continuous and discrete data, does not assume normal distribution</td>\n",
      "    <td>May be computationally expensive for large datasets, may not work well for high-dimensional data</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>PSI</td>\n",
      "    <td>Can detect both magnitude and direction of drift, suitable for both continuous and categorical data</td>\n",
      "    <td>May be sensitive to small changes, may require a large reference dataset</td>\n",
      "  </tr>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "Give pros and cons of using ks-test, t-test, jensen-shannon, wasserstein distance or psi \\\n",
    "for data drift detection as a table.\n",
    "The response should be organized as an HTML table.\n",
    "'''\n",
    "response = get_complet(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a7b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5531440b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "  <tr>\n",
       "    <th>Method</th>\n",
       "    <th>Pros</th>\n",
       "    <th>Cons</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>KS-test</td>\n",
       "    <td>Easy to implement, widely used, suitable for continuous data</td>\n",
       "    <td>Assumes normal distribution, may not work well for small sample sizes</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>t-test</td>\n",
       "    <td>Easy to implement, widely used, suitable for continuous data</td>\n",
       "    <td>Assumes normal distribution, may not work well for small sample sizes, requires equal variances</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Jensen-Shannon</td>\n",
       "    <td>Works well for both continuous and discrete data, does not assume normal distribution</td>\n",
       "    <td>May be computationally expensive for large datasets, may not work well for high-dimensional data</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Wasserstein distance</td>\n",
       "    <td>Works well for both continuous and discrete data, does not assume normal distribution</td>\n",
       "    <td>May be computationally expensive for large datasets, may not work well for high-dimensional data</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>PSI</td>\n",
       "    <td>Can detect both magnitude and direction of drift, suitable for both continuous and categorical data</td>\n",
       "    <td>May be sensitive to small changes, may require a large reference dataset</td>\n",
       "  </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displayplay(HTML(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32746b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python code:\n",
      "\n",
      "import speech_recognition as sr\n",
      "\n",
      "# initialize the recognizer\n",
      "r = sr.Recognizer()\n",
      "\n",
      "# use the microphone as source\n",
      "with sr.Microphone() as source:\n",
      "    print(\"Speak something...\")\n",
      "    audio = r.listen(source)\n",
      "\n",
      "# recognize speech using Google Speech Recognition\n",
      "try:\n",
      "    print(\"You said: \" + r.recognize_google(audio))\n",
      "except sr.UnknownValueError:\n",
      "    print(\"Google Speech Recognition could not understand audio\")\n",
      "except sr.RequestError as e:\n",
      "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
      "\n",
      "C/C++ code:\n",
      "\n",
      "#include <stdio.h>\n",
      "#include <stdlib.h>\n",
      "#include <string.h>\n",
      "#include <sphinxbase/ad.h>\n",
      "#include <pocketsphinx.h>\n",
      "\n",
      "int main(int argc, char *argv[]) {\n",
      "    ps_decoder_t *ps;\n",
      "    cmd_ln_t *config;\n",
      "    FILE *fh;\n",
      "    char const *hyp, *uttid;\n",
      "    int16 buf[512];\n",
      "    int rv;\n",
      "    int32 score;\n",
      "\n",
      "    config = cmd_ln_init(NULL, ps_args(), TRUE,\n",
      "                 \"-hmm\", MODELDIR \"/en-us/en-us\",\n",
      "                 \"-lm\", MODELDIR \"/en-us/en-us.lm.bin\",\n",
      "                 \"-dict\", MODELDIR \"/en-us/cmudict-en-us.dict\",\n",
      "                 NULL);\n",
      "\n",
      "    if (config == NULL) {\n",
      "        fprintf(stderr, \"Failed to create config object, see log for details\\n\");\n",
      "        return -1;\n",
      "    }\n",
      "\n",
      "    ps = ps_init(config);\n",
      "    if (ps == NULL) {\n",
      "        fprintf(stderr, \"Failed to create recognizer, see log for details\\n\");\n",
      "        return -1;\n",
      "    }\n",
      "\n",
      "    fh = fopen(\"test.wav\", \"rb\");\n",
      "    if (fh == NULL) {\n",
      "        fprintf(stderr, \"Unable to open input file\\n\");\n",
      "        return -1;\n",
      "    }\n",
      "\n",
      "    rv = ps_decode_raw(ps, fh, \"test\", -1);\n",
      "    if (rv < 0) {\n",
      "        fprintf(stderr, \"Failed to decode audio file, see log for details\\n\");\n",
      "        return -1;\n",
      "    }\n",
      "\n",
      "    hyp = ps_get_hyp(ps, &score);\n",
      "    printf(\"Recognized: %s\\n\", hyp);\n",
      "\n",
      "    fclose(fh);\n",
      "    ps_free(ps);\n",
      "    cmd_ln_free_r(config);\n",
      "\n",
      "    return 0;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "Write code in python or C/C++ to capture voice commands\n",
    "'''\n",
    "response = get_complet(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506b4ace",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26af6a4",
   "metadata": {},
   "source": [
    "## Expanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997b4dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the sentiment from the lesson on \"inferring\",\n",
    "# and the original customer message, customize the email\n",
    "sentiment = \"negative\"\n",
    "\n",
    "# review for a blender\n",
    "review = f\"\"\"\n",
    "So, they still had the 17 piece system on seasonal \\\n",
    "sale for around $49 in the month of November, about \\\n",
    "half off, but for some reason (call it price gouging) \\\n",
    "around the second week of December the prices all went \\\n",
    "up to about anywhere from between $70-$89 for the same \\\n",
    "system. And the 11 piece system went up around $10 or \\\n",
    "so in price also from the earlier sale price of $29. \\\n",
    "So it looks okay, but if you look at the base, the part \\\n",
    "where the blade locks into place doesn’t look as good \\\n",
    "as in previous editions from a few years ago, but I \\\n",
    "plan to be very gentle with it (example, I crush \\\n",
    "very hard items like beans, ice, rice, etc. in the \\ \n",
    "blender first then pulverize them in the serving size \\\n",
    "I want in the blender then switch to the whipping \\\n",
    "blade for a finer flour, and use the cross cutting blade \\\n",
    "first when making smoothies, then use the flat blade \\\n",
    "if I need them finer/less pulpy). Special tip when making \\\n",
    "smoothies, finely cut and freeze the fruits and \\\n",
    "vegetables (if using spinach-lightly stew soften the \\ \n",
    "spinach then freeze until ready for use-and if making \\\n",
    "sorbet, use a small to medium sized food processor) \\ \n",
    "that you plan to use that way you can avoid adding so \\\n",
    "much ice if at all-when making your smoothie. \\\n",
    "After about a year, the motor was making a funny noise. \\\n",
    "I called customer service but the warranty expired \\\n",
    "already, so I had to buy another one. FYI: The overall \\\n",
    "quality has gone done in these types of products, so \\\n",
    "they are kind of counting on brand recognition and \\\n",
    "consumer loyalty to maintain sales. Got it in about \\\n",
    "two days.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e460bef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear valued customer,\n",
      "\n",
      "Thank you for taking the time to leave a review about our product. We are sorry to hear that you experienced a price increase and that the quality of the product did not meet your expectations. We apologize for any inconvenience this may have caused you.\n",
      "\n",
      "If you have any further concerns or questions, please do not hesitate to reach out to our customer service team. They will be more than happy to assist you in any way they can.\n",
      "\n",
      "Thank you again for your feedback. We appreciate your business and hope to have the opportunity to serve you better in the future.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "AI customer agent\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a customer service AI assistant.\n",
    "Your task is to send an email reply to a valued customer.\n",
    "Given the customer email delimited by ```, \\\n",
    "Generate a reply to thank the customer for their review.\n",
    "If the sentiment is positive or neutral, thank them for \\\n",
    "their review.\n",
    "If the sentiment is negative, apologize and suggest that \\\n",
    "they can reach out to customer service. \n",
    "Make sure to use specific details from the review.\n",
    "Write in a concise and professional tone.\n",
    "Sign the email as `AI customer agent`.\n",
    "Customer review: ```{review}```\n",
    "Review sentiment: {sentiment}\n",
    "\"\"\"\n",
    "response = get_complet(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4026094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Customer,\n",
      "\n",
      "Thank you for taking the time to leave a review. We apologize for any inconvenience you experienced with the pricing of our products. We strive to provide the best value possible to our customers, and we're sorry we fell short in this instance. We appreciate your feedback on the quality of our products and will take it into consideration as we continue to improve.\n",
      "\n",
      "We understand your frustration with the motor issue you experienced, and we apologize for any inconvenience this may have caused. If you have any further concerns, please do not hesitate to reach out to our customer service team for assistance. They will be more than happy to help you resolve any issues you may have.\n",
      "\n",
      "Thank you again for your feedback, and we hope to have the opportunity to serve you better in the future.\n",
      "\n",
      "Best regards,\n",
      "AI customer agent\n"
     ]
    }
   ],
   "source": [
    "prompt2 = f\"\"\"\n",
    "You are a customer service AI assistant.\n",
    "Your task is to send an email reply to a valued customer.\n",
    "Given the customer email delimited by ```, \\\n",
    "Generate a reply to thank the customer for their review.\n",
    "If the sentiment is positive or neutral, thank them for \\\n",
    "their review.\n",
    "If the sentiment is negative, apologize and suggest that \\\n",
    "they can reach out to customer service. \n",
    "Make sure to use specific details from the review.\n",
    "Write in a concise and professional tone.\n",
    "Sign the email as `AI customer agent`.\n",
    "Customer review: ```{review}```\n",
    "Review sentiment: {sentiment}\n",
    "\"\"\"\n",
    "response = get_complet(prompt2, temperature=0.7)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f815740",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783867cd",
   "metadata": {},
   "source": [
    "## ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b0d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "#     print(str(response.choices[0].message))\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a432ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_messages(_):\n",
    "    prompt = inp.value_input\n",
    "    inp.value = ''\n",
    "    context.append({'role':'user', 'content':f\"{prompt}\"})\n",
    "    response = get_completion_from_messages(context) \n",
    "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
    "    panels.append(\n",
    "        pn.Row('User:', pn.pane.Markdown(prompt, width=600)))\n",
    "    panels.append(\n",
    "        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'})))\n",
    " \n",
    "    return pn.Column(*panels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a78e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import panel as pn  # GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53818929",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.extension()\n",
    "\n",
    "panels = [] # collect display \n",
    "\n",
    "context = [ {'role':'system', 'content':\"\"\"\n",
    "You are OrderBot, an automated service to collect orders for a pizza restaurant. \\\n",
    "You first greet the customer, then collects the order, \\\n",
    "and then asks if it's a pickup or delivery. \\\n",
    "You wait to collect the entire order, then summarize it and check for a final \\\n",
    "time if the customer wants to add anything else. \\\n",
    "If it's a delivery, you ask for an address. \\\n",
    "Finally you collect the payment.\\\n",
    "Make sure to clarify all options, extras and sizes to uniquely \\\n",
    "identify the item from the menu.\\\n",
    "You respond in a short, very conversational friendly style. \\\n",
    "The menu includes \\\n",
    "pepperoni pizza  12.95, 10.00, 7.00 \\\n",
    "cheese pizza   10.95, 9.25, 6.50 \\\n",
    "eggplant pizza   11.95, 9.75, 6.75 \\\n",
    "fries 4.50, 3.50 \\\n",
    "greek salad 7.25 \\\n",
    "Toppings: \\\n",
    "extra cheese 2.00, \\\n",
    "mushrooms 1.50 \\\n",
    "sausage 3.00 \\\n",
    "canadian bacon 3.50 \\\n",
    "AI sauce 1.50 \\\n",
    "peppers 1.00 \\\n",
    "Drinks: \\\n",
    "coke 3.00, 2.00, 1.00 \\\n",
    "sprite 3.00, 2.00, 1.00 \\\n",
    "bottled water 5.00 \\\n",
    "\"\"\"} ]  # accumulate messages\n",
    "\n",
    "\n",
    "inp = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text here…')\n",
    "button_conversation = pn.widgets.Button(name=\"Chat!\")\n",
    "\n",
    "interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    inp,\n",
    "    pn.Row(button_conversation),\n",
    "    pn.panel(interactive_conversation, loading_indicator=True, height=300),\n",
    ")\n",
    "\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc20ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages =  context.copy()\n",
    "messages.append(\n",
    "{'role':'system', 'content':'create a json summary of the previous food order. Itemize the price for each item\\\n",
    " The fields should be 1) pizza, include size 2) list of toppings 3) list of drinks, include size   4) list of sides include size  5)total price '},    \n",
    ")\n",
    " #The fields should be 1) pizza, price 2) list of toppings 3) list of drinks, include size include price  4) list of sides include size include price, 5)total price '},    \n",
    "\n",
    "response = get_completion_from_messages(messages, temperature=0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b325cb15",
   "metadata": {},
   "source": [
    "[back to top](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
